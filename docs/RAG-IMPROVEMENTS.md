# RAG Improvements Roadmap

‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö RAG ‡∏Ç‡∏≠‡∏á Thudong MCP Server

---

## Executive Summary

| Priority | Issue | Impact | Effort | Status |
|----------|-------|--------|--------|--------|
| üî¥ High | Thai Tokenization | ‡∏ú‡∏•‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö | Medium | üìã Planned |
| üî¥ High | Synonym Expansion | Miss related content | Low | üìã Planned |
| üü° Medium | Vector Search | No semantic match | High | üìã Planned |
| üü° Medium | Query Cache | Performance | Low | üìã Planned |
| üü¢ Low | Text Chunking | Context precision | Medium | üìã Planned |
| üü¢ Low | Feedback Loop | Continuous improvement | Medium | üìã Planned |

---

## Issue 1: Thai Tokenization (üî¥ High Priority)

### Problem

‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ä‡πâ FTS5 tokenizer `unicode61` ‡∏ã‡∏∂‡πà‡∏á‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≤‡∏° whitespace/punctuation:

```javascript
// db.js:74-80
CREATE VIRTUAL TABLE responses_fts USING fts5(
    impressed_text,
    suggestion_text,
    content='responses',
    content_rowid='id',
    tokenize='unicode61 remove_diacritics 2'  // ‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
);
```

### Impact

- ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ word boundary ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
- "‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥" ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà match "‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏™‡∏∞‡∏≠‡∏≤‡∏î" ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ space
- "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π‡πÅ‡∏•‡∏î‡∏µ" ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å tokenize ‡πÄ‡∏õ‡πá‡∏ô 1 token ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á", "‡∏î‡∏π‡πÅ‡∏•", "‡∏î‡∏µ"

### Example

```
Input: "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π‡πÅ‡∏•‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏Ñ‡∏£‡∏±‡∏ö"

unicode61 tokenization:
  ‚Üí ["‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π‡πÅ‡∏•‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏Ñ‡∏£‡∏±‡∏ö"]  // 1 token (wrong)

Correct Thai tokenization:
  ‚Üí ["‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á", "‡∏î‡∏π‡πÅ‡∏•", "‡∏î‡∏µ", "‡∏°‡∏≤‡∏Å", "‡∏Ñ‡∏£‡∏±‡∏ö"]  // 5 tokens
```

### Solution Options

#### Option A: ICU Tokenizer (Best, but requires recompile)

```sql
-- ‡∏ï‡πâ‡∏≠‡∏á compile SQLite with ICU extension
tokenize='icu th_TH'
```

**Pros:** Native Thai word segmentation
**Cons:** ‡∏ï‡πâ‡∏≠‡∏á compile SQLite ‡πÉ‡∏´‡∏°‡πà, Docker image ‡∏à‡∏∞‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô

#### Option B: Pre-tokenize with Python (Recommended)

```python
# preprocessing script using pythainlp
from pythainlp.tokenize import word_tokenize

def tokenize_thai(text):
    tokens = word_tokenize(text, engine='newmm')
    return ' '.join(tokens)

# Before insert:
# "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π‡πÅ‡∏•‡∏î‡∏µ‡∏°‡∏≤‡∏Å" ‚Üí "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á ‡∏î‡∏π‡πÅ‡∏• ‡∏î‡∏µ ‡∏°‡∏≤‡∏Å"
```

```javascript
// import.js - Add preprocessing step
function preprocessThaiText(text) {
    // Call Python script or use node-pythainlp binding
    return tokenizedText;
}
```

**Pros:** ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö SQLite ‡∏õ‡∏Å‡∏ï‡∏¥
**Cons:** ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏° preprocessing step, Python dependency

#### Option C: Trigram Tokenizer (Quick fix)

```sql
tokenize='trigram'
```

**Pros:** ‡∏á‡πà‡∏≤‡∏¢, fuzzy match ‡πÑ‡∏î‡πâ
**Cons:** Index ‡πÉ‡∏´‡∏ç‡πà, ‡∏≠‡∏≤‡∏à match ‡∏ú‡∏¥‡∏î (false positives)

### Implementation Plan

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Thai Tokenization Pipeline                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

  Raw Text                Pre-tokenize              FTS5 Index
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ              ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ              ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π‡πÅ‡∏•‡∏î‡∏µ"  ‚Üí   pythainlp/deepcut   ‚Üí   "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á ‡∏î‡∏π‡πÅ‡∏• ‡∏î‡∏µ"
                              ‚îÇ
                              ‚ñº
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ  Token Mapping  ‚îÇ
                     ‚îÇ  Table (optional)‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Files to Modify

- `src/import.js` - Add tokenization during import
- `src/db.js` - Update FTS5 schema
- `package.json` - Add tokenization dependency
- New: `src/tokenizer.js` - Thai tokenization wrapper

---

## Issue 2: No Synonym Expansion (üî¥ High Priority)

### Problem

Query ‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡∏ï‡∏£‡∏á‡πÜ ‡πÑ‡∏õ FTS5 ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ synonym handling:

```javascript
// db.js:185-201
export function searchFeedback(query, type = 'all', limit = 10) {
    // ...
    const stmt = db.prepare(`
        SELECT ...
        WHERE responses_fts MATCH ?  // ‚ùå Raw query, no expansion
        ...
    `);
    return stmt.all(query, limit);  // query ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å expand
}
```

### Impact

- "‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥" ‡πÑ‡∏°‡πà match "‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏∏‡∏Ç‡∏≤" ‡∏´‡∏£‡∏∑‡∏≠ "toilet"
- "‡∏≠‡∏≤‡∏´‡∏≤‡∏£" ‡πÑ‡∏°‡πà match "‡∏Ç‡πâ‡∏≤‡∏ß" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≤‡∏ß"
- "‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å" ‡πÑ‡∏°‡πà match "‡πÄ‡∏ï‡πá‡∏ô‡∏ó‡πå" ‡∏´‡∏£‡∏∑‡∏≠ "‡πÄ‡∏ï‡πâ‡∏ô‡∏ó‡πå"

### Solution

```javascript
// src/synonyms.js (New file)

export const THAI_SYNONYMS = {
    // Facilities
    '‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥': ['‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥', '‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏∏‡∏Ç‡∏≤', '‡∏™‡∏∏‡∏Ç‡∏≤', 'toilet', '‡∏™‡πâ‡∏ß‡∏°', '‡∏´‡πâ‡∏≠‡∏á‡∏≠‡∏≤‡∏ö‡∏ô‡πâ‡∏≥'],
    '‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å': ['‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å', '‡πÄ‡∏ï‡πá‡∏ô‡∏ó‡πå', '‡πÄ‡∏ï‡πâ‡∏ô‡∏ó‡πå', '‡∏ó‡∏µ‡πà‡∏ô‡∏≠‡∏ô', '‡∏´‡πâ‡∏≠‡∏á‡∏û‡∏±‡∏Å', 'tent'],
    '‡∏≠‡∏≤‡∏´‡∏≤‡∏£': ['‡∏≠‡∏≤‡∏´‡∏≤‡∏£', '‡∏Ç‡πâ‡∏≤‡∏ß', '‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≤‡∏ß', '‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏ä‡πâ‡∏≤', '‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Å‡∏•‡∏≤‡∏á‡∏ß‡∏±‡∏ô', '‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏¢‡πá‡∏ô', '‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°', '‡∏ô‡πâ‡∏≥'],

    // People
    '‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á': ['‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á', '‡∏û‡∏µ‡πà‡πÜ', '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô', 'staff', '‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•', '‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà'],
    '‡∏û‡∏£‡∏∞‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå': ['‡∏û‡∏£‡∏∞‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå', '‡∏´‡∏•‡∏ß‡∏á‡∏û‡πà‡∏≠', '‡∏û‡∏£‡∏∞', '‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå', '‡∏ó‡πà‡∏≤‡∏ô'],

    // Activities
    '‡∏ò‡∏∏‡∏î‡∏á‡∏Ñ‡πå': ['‡∏ò‡∏∏‡∏î‡∏á‡∏Ñ‡πå', '‡πÄ‡∏î‡∏¥‡∏ô‡∏ò‡∏∏‡∏î‡∏á‡∏Ñ‡πå', '‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô', '‡πÄ‡∏î‡∏¥‡∏ô‡∏õ‡πà‡∏≤', '‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á'],
    '‡∏™‡∏°‡∏≤‡∏ò‡∏¥': ['‡∏™‡∏°‡∏≤‡∏ò‡∏¥', '‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥', '‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥', '‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°', 'meditation'],

    // Places
    '‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà': ['‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà', '‡∏ß‡∏±‡∏î', '‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà', 'location'],

    // Events
    '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£': ['‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£', '‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏ß‡∏•‡∏≤', 'schedule', '‡πÄ‡∏ß‡∏•‡∏≤', '‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°'],
    '‡∏û‡∏¥‡∏ò‡∏µ': ['‡∏û‡∏¥‡∏ò‡∏µ', '‡∏®‡∏≤‡∏™‡∏ô‡∏û‡∏¥‡∏ò‡∏µ', '‡∏û‡∏¥‡∏ò‡∏µ‡∏Å‡∏£‡∏£‡∏°', 'ceremony'],

    // Common issues
    '‡∏Ñ‡∏¥‡∏ß': ['‡∏Ñ‡∏¥‡∏ß', '‡πÅ‡∏ñ‡∏ß', '‡∏£‡∏≠', '‡∏£‡∏≠‡∏Ñ‡∏¥‡∏ß', '‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏ñ‡∏ß', 'queue'],
    '‡∏™‡∏∏‡∏ô‡∏±‡∏Ç': ['‡∏™‡∏∏‡∏ô‡∏±‡∏Ç', '‡∏´‡∏°‡∏≤', 'dog', '‡∏™‡∏±‡∏ï‡∏ß‡πå'],
    '‡∏´‡∏¥‡∏ô': ['‡∏´‡∏¥‡∏ô', '‡∏û‡∏∑‡πâ‡∏ô', '‡∏ó‡∏≤‡∏á', '‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á', '‡∏ñ‡∏ô‡∏ô'],
};

/**
 * Expand query with synonyms
 * @param {string} query - Original query
 * @returns {string} - FTS5 query with OR expansion
 */
export function expandQuery(query) {
    const normalizedQuery = query.trim().toLowerCase();

    // Check if query matches any synonym group
    for (const [key, synonyms] of Object.entries(THAI_SYNONYMS)) {
        if (synonyms.some(s => normalizedQuery.includes(s.toLowerCase()))) {
            // Build FTS5 OR query
            return synonyms.map(s => `"${s}"`).join(' OR ');
        }
    }

    // No synonyms found, return original
    return query;
}

/**
 * Expand query with fuzzy matching
 * @param {string} query - Original query
 * @returns {string} - FTS5 query with wildcards
 */
export function fuzzyQuery(query) {
    // Add prefix matching
    return `${query}*`;
}
```

### Update db.js

```javascript
// db.js
import { expandQuery } from './synonyms.js';

export function searchFeedback(query, type = 'all', limit = 10) {
    const db = getDb();

    // ‚úÖ Expand query with synonyms
    const expandedQuery = expandQuery(query);

    const stmt = db.prepare(`
        SELECT ...
        WHERE responses_fts MATCH ?
        ...
    `);

    return stmt.all(expandedQuery, limit);
}
```

### Files to Create/Modify

- New: `src/synonyms.js` - Synonym definitions and expansion
- Modify: `src/db.js` - Use expandQuery()
- Modify: `src/index.js` - Log expanded queries for debugging

---

## Issue 3: No Semantic/Vector Search (üü° Medium Priority)

### Problem

FTS5 ‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà keyword matching (BM25) ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢:

```
Query: "‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢"
FTS5 matches: records containing "‡∏≠‡∏≤‡∏´‡∏≤‡∏£" or "‡∏≠‡∏£‡πà‡∏≠‡∏¢"
Misses: "‡∏Ç‡πâ‡∏≤‡∏ß‡∏°‡∏±‡∏ô‡πÑ‡∏Å‡πà‡∏£‡∏™‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°", "‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≤‡∏ß‡∏ñ‡∏π‡∏Å‡∏õ‡∏≤‡∏Å"
```

### Solution Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         HYBRID SEARCH ARCHITECTURE                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

  User Query: "‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢"
        ‚îÇ
        ‚ñº
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ                        QUERY PROCESSOR                                   ‚îÇ
  ‚îÇ  1. Synonym expansion: "‡∏≠‡∏≤‡∏´‡∏≤‡∏£ OR ‡∏Ç‡πâ‡∏≤‡∏ß OR ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≤‡∏ß"                       ‚îÇ
  ‚îÇ  2. Generate embedding: query ‚Üí vector [0.1, 0.3, ...]                  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                                    ‚îÇ
        ‚ñº                                    ‚ñº
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ   FTS5 Search    ‚îÇ              ‚îÇ  Vector Search   ‚îÇ
  ‚îÇ   (Keyword)      ‚îÇ              ‚îÇ  (Semantic)      ‚îÇ
  ‚îÇ                  ‚îÇ              ‚îÇ                  ‚îÇ
  ‚îÇ  BM25 scoring    ‚îÇ              ‚îÇ  Cosine similarity‚îÇ
  ‚îÇ  Fast, exact     ‚îÇ              ‚îÇ  Understands meaning‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                                  ‚îÇ
           ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   RESULT FUSION    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                    ‚îÇ
                ‚îÇ  Reciprocal Rank   ‚îÇ
                ‚îÇ  Fusion (RRF)      ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   FINAL RESULTS    ‚îÇ
                ‚îÇ   (Re-ranked)      ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Implementation Options

#### Option A: sqlite-vss (SQLite Vector Extension)

```javascript
// Requires sqlite-vss extension
import Database from 'better-sqlite3';

const db = new Database('thudong.db');
db.loadExtension('./vss0');

// Create vector table
db.exec(`
    CREATE VIRTUAL TABLE responses_vec USING vss0(
        embedding(384)  -- dimension depends on model
    );
`);

// Search
const results = db.prepare(`
    SELECT rowid, distance
    FROM responses_vec
    WHERE vss_search(embedding, ?)
    LIMIT 10
`).all(queryEmbedding);
```

**Pros:** All-in-one SQLite solution
**Cons:** Experimental, requires extension loading

#### Option B: Separate Vector DB (Recommended for production)

```javascript
// Using Chroma (local) or Pinecone (cloud)
import { ChromaClient } from 'chromadb';

const client = new ChromaClient();
const collection = await client.getOrCreateCollection({
    name: 'thudong_feedback',
    metadata: { 'hnsw:space': 'cosine' }
});

// Add documents with embeddings
await collection.add({
    ids: ['1', '2', '3'],
    embeddings: [[0.1, 0.2, ...], [0.3, 0.4, ...], ...],
    documents: ['‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π‡πÅ‡∏•‡∏î‡∏µ', '‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢', ...],
    metadatas: [{ type: 'impressed' }, ...]
});

// Search
const results = await collection.query({
    queryEmbeddings: [queryVector],
    nResults: 10
});
```

#### Option C: Simple Embedding with OpenAI

```javascript
// src/embedding.js
import OpenAI from 'openai';

const openai = new OpenAI();

export async function getEmbedding(text) {
    const response = await openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: text,
    });
    return response.data[0].embedding;
}

export function cosineSimilarity(a, b) {
    const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
    const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
    const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
    return dotProduct / (magnitudeA * magnitudeB);
}
```

### Hybrid Search Implementation

```javascript
// src/hybrid-search.js
import { searchFeedback } from './db.js';
import { vectorSearch } from './vector-db.js';

export async function hybridSearch(query, limit = 10) {
    // Run both searches in parallel
    const [ftsResults, vecResults] = await Promise.all([
        searchFeedback(query, 'all', limit * 2),
        vectorSearch(query, limit * 2)
    ]);

    // Reciprocal Rank Fusion
    const scores = new Map();
    const k = 60; // RRF constant

    ftsResults.forEach((result, rank) => {
        const id = result.id;
        scores.set(id, (scores.get(id) || 0) + 1 / (k + rank + 1));
    });

    vecResults.forEach((result, rank) => {
        const id = result.id;
        scores.set(id, (scores.get(id) || 0) + 1 / (k + rank + 1));
    });

    // Sort by combined score
    const sortedIds = [...scores.entries()]
        .sort((a, b) => b[1] - a[1])
        .slice(0, limit)
        .map(([id]) => id);

    // Fetch full records
    return getRecordsByIds(sortedIds);
}
```

### Files to Create

- New: `src/embedding.js` - Embedding generation
- New: `src/vector-db.js` - Vector database operations
- New: `src/hybrid-search.js` - Combined search
- Modify: `src/db.js` - Add vector storage columns
- Modify: `src/import.js` - Generate embeddings during import

---

## Issue 4: No Query Cache (üü° Medium Priority)

### Problem

‡∏ó‡∏∏‡∏Å query run SQL ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡πÅ‡∏°‡πâ query ‡πÄ‡∏î‡∏¥‡∏°‡∏ã‡πâ‡∏≥‡πÜ

### Solution

```javascript
// src/cache.js
import { LRUCache } from 'lru-cache';

const queryCache = new LRUCache({
    max: 500,                    // Max entries
    ttl: 1000 * 60 * 10,        // 10 minutes TTL
    updateAgeOnGet: true,        // Reset TTL on access
});

export function getCached(key) {
    return queryCache.get(key);
}

export function setCache(key, value) {
    queryCache.set(key, value);
}

export function generateCacheKey(tool, args) {
    return `${tool}:${JSON.stringify(args)}`;
}

export function clearCache() {
    queryCache.clear();
}
```

### Update db.js

```javascript
// db.js
import { getCached, setCache, generateCacheKey } from './cache.js';

export function searchFeedback(query, type = 'all', limit = 10) {
    const cacheKey = generateCacheKey('search', { query, type, limit });

    // Check cache first
    const cached = getCached(cacheKey);
    if (cached) {
        return cached;
    }

    // Execute query
    const results = executeSearch(query, type, limit);

    // Cache results
    setCache(cacheKey, results);

    return results;
}
```

### Files to Create/Modify

- New: `src/cache.js` - LRU cache implementation
- Modify: `src/db.js` - Add caching to all query functions
- Modify: `package.json` - Add `lru-cache` dependency

---

## Issue 5: No Text Chunking (üü¢ Low Priority)

### Problem

‡∏ö‡∏≤‡∏á record ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏°‡∏≤‡∏Å ‡∏ó‡∏≥‡πÉ‡∏´‡πâ:
- BM25 score ‡∏ñ‡∏π‡∏Å dilute
- AI ‡∏≠‡πà‡∏≤‡∏ô context ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏à‡∏∏‡∏î
- Embedding ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏•‡∏≤‡∏¢ topics

### Example

```
Current (1 record):
{
  id: 42,
  impressed_text: "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π‡πÅ‡∏•‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡πÉ‡∏™‡πà‡πÉ‡∏à‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å
                   ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≤‡∏ß‡∏°‡∏±‡∏ô‡πÑ‡∏Å‡πà ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° ‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡∏î‡∏µ
                   ‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ò‡∏∏‡∏î‡∏á‡∏Ñ‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ ‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ò‡∏£‡∏£‡∏°‡∏∞..."
}

Better (multiple chunks):
{
  chunk_id: 1,
  source_id: 42,
  text: "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π‡πÅ‡∏•‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡πÉ‡∏™‡πà‡πÉ‡∏à‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô",
  topic: "‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á"
}
{
  chunk_id: 2,
  source_id: 42,
  text: "‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≤‡∏ß‡∏°‡∏±‡∏ô‡πÑ‡∏Å‡πà",
  topic: "‡∏≠‡∏≤‡∏´‡∏≤‡∏£"
}
...
```

### Solution

```javascript
// src/chunker.js

const TOPIC_KEYWORDS = {
    '‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á': ['‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á', '‡∏û‡∏µ‡πà‡πÜ', '‡∏î‡∏π‡πÅ‡∏•', '‡πÉ‡∏™‡πà‡πÉ‡∏à'],
    '‡∏≠‡∏≤‡∏´‡∏≤‡∏£': ['‡∏≠‡∏≤‡∏´‡∏≤‡∏£', '‡∏Ç‡πâ‡∏≤‡∏ß', '‡∏≠‡∏£‡πà‡∏≠‡∏¢', '‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°'],
    '‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà': ['‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà', '‡∏ß‡∏±‡∏î', '‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®', '‡∏™‡∏ß‡∏¢'],
    '‡∏ò‡∏∏‡∏î‡∏á‡∏Ñ‡πå': ['‡∏ò‡∏∏‡∏î‡∏á‡∏Ñ‡πå', '‡πÄ‡∏î‡∏¥‡∏ô', '‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå'],
    '‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥': ['‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥', '‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏∏‡∏Ç‡∏≤', '‡∏™‡∏∞‡∏≠‡∏≤‡∏î'],
    '‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å': ['‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å', '‡πÄ‡∏ï‡πá‡∏ô‡∏ó‡πå', '‡∏ô‡∏≠‡∏ô'],
};

export function chunkText(text, sourceId) {
    if (!text || text.length < 50) {
        return [{ source_id: sourceId, text, topic: 'general' }];
    }

    const chunks = [];

    // Split by common delimiters
    const sentences = text.split(/[,ÿå„ÄÅÔºå„ÄÇÔºé.!\n]/);

    for (const sentence of sentences) {
        const trimmed = sentence.trim();
        if (trimmed.length < 10) continue;

        // Detect topic
        const topic = detectTopic(trimmed);

        chunks.push({
            source_id: sourceId,
            text: trimmed,
            topic
        });
    }

    return chunks.length > 0 ? chunks : [{ source_id: sourceId, text, topic: 'general' }];
}

function detectTopic(text) {
    for (const [topic, keywords] of Object.entries(TOPIC_KEYWORDS)) {
        if (keywords.some(kw => text.includes(kw))) {
            return topic;
        }
    }
    return 'general';
}
```

### New Schema

```sql
-- Additional table for chunks
CREATE TABLE response_chunks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id INTEGER REFERENCES responses(id),
    text TEXT,
    topic TEXT,
    field_type TEXT  -- 'impressed' or 'suggestion'
);

CREATE VIRTUAL TABLE chunks_fts USING fts5(
    text,
    content='response_chunks',
    content_rowid='id',
    tokenize='unicode61'
);

CREATE INDEX idx_chunks_topic ON response_chunks(topic);
CREATE INDEX idx_chunks_source ON response_chunks(source_id);
```

---

## Issue 6: No Feedback Loop (üü¢ Low Priority)

### Problem

‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö user feedback ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á ranking

### Solution

```sql
-- New table for tracking
CREATE TABLE search_analytics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    query TEXT,
    tool_name TEXT,
    result_ids TEXT,  -- JSON array of returned IDs
    timestamp TEXT,
    session_id TEXT
);

CREATE TABLE result_feedback (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    search_id INTEGER REFERENCES search_analytics(id),
    result_id INTEGER,
    was_useful BOOLEAN,
    feedback_type TEXT,  -- 'click', 'copy', 'thumbs_up', 'thumbs_down'
    timestamp TEXT
);
```

### Usage Analytics Tool

```javascript
// New MCP tool
{
    name: 'log_feedback',
    description: '‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å feedback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤',
    inputSchema: {
        type: 'object',
        properties: {
            search_id: { type: 'integer' },
            result_id: { type: 'integer' },
            was_useful: { type: 'boolean' }
        },
        required: ['search_id', 'result_id', 'was_useful']
    }
}
```

---

## Implementation Roadmap

### Phase 1: Quick Wins (Week 1)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Task                              ‚îÇ Effort ‚îÇ Impact ‚îÇ Status  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Add synonym expansion          ‚îÇ 2h     ‚îÇ High   ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  2. Add query cache (LRU)          ‚îÇ 2h     ‚îÇ Medium ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  3. Log queries for analytics      ‚îÇ 1h     ‚îÇ Low    ‚îÇ ‚òê Todo  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Phase 2: Thai Language (Week 2-3)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Task                              ‚îÇ Effort ‚îÇ Impact ‚îÇ Status  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Research Thai tokenizers       ‚îÇ 4h     ‚îÇ -      ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  2. Implement pre-tokenization     ‚îÇ 8h     ‚îÇ High   ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  3. Re-import data with tokens     ‚îÇ 2h     ‚îÇ High   ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  4. Test search quality            ‚îÇ 4h     ‚îÇ -      ‚îÇ ‚òê Todo  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Phase 3: Semantic Search (Week 4-6)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Task                              ‚îÇ Effort ‚îÇ Impact ‚îÇ Status  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Choose embedding model         ‚îÇ 4h     ‚îÇ -      ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  2. Set up vector storage          ‚îÇ 8h     ‚îÇ High   ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  3. Generate embeddings for data   ‚îÇ 4h     ‚îÇ -      ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  4. Implement hybrid search        ‚îÇ 8h     ‚îÇ High   ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  5. Tune RRF parameters            ‚îÇ 4h     ‚îÇ Medium ‚îÇ ‚òê Todo  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Phase 4: Advanced Features (Week 7+)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Task                              ‚îÇ Effort ‚îÇ Impact ‚îÇ Status  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Implement text chunking        ‚îÇ 8h     ‚îÇ Medium ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  2. Add topic clustering           ‚îÇ 8h     ‚îÇ Medium ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  3. Feedback tracking system       ‚îÇ 8h     ‚îÇ Low    ‚îÇ ‚òê Todo  ‚îÇ
‚îÇ  4. Auto-tuning based on feedback  ‚îÇ 16h    ‚îÇ Medium ‚îÇ ‚òê Todo  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Quick Start: Synonym Expansion

‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ:

### Step 1: Create synonyms.js

```bash
touch src/synonyms.js
```

### Step 2: Add code

```javascript
// src/synonyms.js
export const THAI_SYNONYMS = {
    '‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥': ['‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥', '‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏∏‡∏Ç‡∏≤', '‡∏™‡∏∏‡∏Ç‡∏≤', 'toilet'],
    '‡∏≠‡∏≤‡∏´‡∏≤‡∏£': ['‡∏≠‡∏≤‡∏´‡∏≤‡∏£', '‡∏Ç‡πâ‡∏≤‡∏ß', '‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≤‡∏ß', '‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏ä‡πâ‡∏≤', '‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Å‡∏•‡∏≤‡∏á‡∏ß‡∏±‡∏ô'],
    '‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å': ['‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å', '‡πÄ‡∏ï‡πá‡∏ô‡∏ó‡πå', '‡πÄ‡∏ï‡πâ‡∏ô‡∏ó‡πå', '‡∏ó‡∏µ‡πà‡∏ô‡∏≠‡∏ô'],
    '‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á': ['‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á', '‡∏û‡∏µ‡πà‡πÜ', '‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô', 'staff'],
};

export function expandQuery(query) {
    for (const [key, synonyms] of Object.entries(THAI_SYNONYMS)) {
        if (query.includes(key) || synonyms.some(s => query.includes(s))) {
            return synonyms.map(s => `"${s}"`).join(' OR ');
        }
    }
    return query;
}
```

### Step 3: Update db.js

```javascript
import { expandQuery } from './synonyms.js';

export function searchFeedback(query, type = 'all', limit = 10) {
    const expandedQuery = expandQuery(query);
    // ... rest of function
}
```

### Step 4: Test

```bash
npm run start
# Query: "‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥" should now also find "‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏∏‡∏Ç‡∏≤", "‡∏™‡∏∏‡∏Ç‡∏≤" etc.
```

---

## References

- [SQLite FTS5](https://www.sqlite.org/fts5.html)
- [PyThaiNLP](https://pythainlp.github.io/)
- [sqlite-vss](https://github.com/asg017/sqlite-vss)
- [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)

---

*Last updated: 2025-12-15*
